Okay, let's outline a backend design for the Workflow Engine using Django and Django Rest Framework (DRF). This design aims to be modular and scalable.

**I. Django Models (`models.py`)**

We need models to store the workflow structure (Definitions), their running states (Instances), and the tasks generated.

```python
# workflows/models.py
from django.db import models
from django.conf import settings
from django.contrib.contenttypes.fields import GenericForeignKey
from django.contrib.contenttypes.models import ContentType
from django.utils.translation import gettext_lazy as _
import uuid

# --- Workflow Definition ---
class WorkflowDefinition(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=255, unique=True, help_text=_("Unique name for the workflow definition"))
    description = models.TextField(blank=True, null=True)
    # Stores the graph structure (nodes, edges, positions) from the frontend designer
    definition_json = models.JSONField(help_text=_("JSON representation of the workflow graph"))
    version = models.PositiveIntegerField(default=1)
    is_active = models.BooleanField(default=True, help_text=_("Whether this definition can be used to start new instances"))
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        unique_together = ('name', 'version') # Allow multiple versions of the same workflow name
        ordering = ('name', '-version')

    def __str__(self):
        return f"{self.name} (v{self.version})"

# --- Workflow Instance ---
class WorkflowInstance(models.Model):
    class Status(models.TextChoices):
        PENDING = 'PENDING', _('Pending')
        RUNNING = 'RUNNING', _('Running')
        COMPLETED = 'COMPLETED', _('Completed')
        FAILED = 'FAILED', _('Failed')
        CANCELED = 'CANCELED', _('Canceled')
        SUSPENDED = 'SUSPENDED', _('Suspended') # For manual intervention or long waits

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    definition = models.ForeignKey(WorkflowDefinition, on_delete=models.PROTECT, related_name='instances')
    status = models.CharField(max_length=20, choices=Status.choices, default=Status.PENDING)
    # Stores the dynamic data associated with this specific run (e.g., leave request details)
    payload = models.JSONField(default=dict, help_text=_("Data payload for this workflow instance"))
    # Stores the ID(s) of the currently active node(s) in the definition_json
    # Can be a list if the workflow has parallel paths
    current_node_ids = models.JSONField(default=list, help_text=_("List of active node IDs in the definition"))
    started_at = models.DateTimeField(auto_now_add=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    # Optional: Link to the object that triggered this workflow (e.g., a LeaveRequest)
    content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE, null=True, blank=True)
    object_id = models.UUIDField(null=True, blank=True) # Assuming UUID PKs for related objects
    triggered_by_object = GenericForeignKey('content_type', 'object_id')

    class Meta:
        ordering = ('-started_at',)

    def __str__(self):
        return f"Instance {self.id} ({self.definition.name} v{self.definition.version}) - {self.status}"

# --- Workflow Task (User Tasks like Approvals) ---
class WorkflowTask(models.Model):
    class Status(models.TextChoices):
        PENDING = 'PENDING', _('Pending')
        ASSIGNED = 'ASSIGNED', _('Assigned') # User claimed it (if applicable)
        COMPLETED = 'COMPLETED', _('Completed')
        CANCELED = 'CANCELED', _('Canceled') # Workflow path changed, task no longer needed

    class AssigneeType(models.TextChoices):
        USER = 'USER', _('Specific User')
        ROLE = 'ROLE', _('Role/Group')
        RULE = 'RULE', _('Rule Based') # e.g., 'RequesterManager'

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    instance = models.ForeignKey(WorkflowInstance, on_delete=models.CASCADE, related_name='tasks')
    # ID of the node in definition_json that generated this task
    node_id = models.CharField(max_length=255, help_text=_("Node ID from the workflow definition"))
    task_type = models.CharField(max_length=50, default='APPROVAL', help_text=_("Type of task, e.g., APPROVAL, FORM_ENTRY"))
    status = models.CharField(max_length=20, choices=Status.choices, default=Status.PENDING)

    # Assignee Info
    assignee_type = models.CharField(max_length=20, choices=AssigneeType.choices)
    # Stores user ID, role name, or rule identifier based on assignee_type
    assignee_identifier = models.CharField(max_length=255, help_text=_("User ID, Role name, or Rule identifier"))
    # Optional: Link to actual users once assigned/claimed (especially useful for ROLE type)
    assigned_users = models.ManyToManyField(settings.AUTH_USER_MODEL, blank=True, related_name='workflow_tasks')

    # Task Metadata
    due_date = models.DateTimeField(null=True, blank=True)
    # Stores the result of the task completion, e.g., 'approved', 'rejected', custom outcomes
    outcome = models.CharField(max_length=100, null=True, blank=True)
    # Stores data submitted with task completion (e.g., approval comments, form data)
    completion_data = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    completed_at = models.DateTimeField(null=True, blank=True)
    completed_by = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET_NULL, null=True, blank=True, related_name='+')

    class Meta:
        ordering = ('created_at',)

    def __str__(self):
        return f"Task {self.id} for Instance {self.instance.id} ({self.node_id}) - {self.status}"


# --- Workflow History (Optional but Recommended for Auditing) ---
class WorkflowHistory(models.Model):
    class EventType(models.TextChoices):
        INSTANCE_STARTED = 'INSTANCE_STARTED', _('Instance Started')
        INSTANCE_COMPLETED = 'INSTANCE_COMPLETED', _('Instance Completed')
        INSTANCE_FAILED = 'INSTANCE_FAILED', _('Instance Failed')
        INSTANCE_CANCELED = 'INSTANCE_CANCELED', _('Instance Canceled')
        NODE_ENTERED = 'NODE_ENTERED', _('Node Entered')
        NODE_EXITED = 'NODE_EXITED', _('Node Exited') # Usually when moving to the next
        TASK_CREATED = 'TASK_CREATED', _('Task Created')
        TASK_ASSIGNED = 'TASK_ASSIGNED', _('Task Assigned/Claimed')
        TASK_COMPLETED = 'TASK_COMPLETED', _('Task Completed')
        TASK_TIMED_OUT = 'TASK_TIMED_OUT', _('Task Timed Out')
        COMMENT_ADDED = 'COMMENT_ADDED', _('Comment Added') # General purpose comment

    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    instance = models.ForeignKey(WorkflowInstance, on_delete=models.CASCADE, related_name='history_logs')
    node_id = models.CharField(max_length=255, null=True, blank=True, help_text=_("Relevant Node ID, if applicable"))
    task = models.ForeignKey(WorkflowTask, on_delete=models.SET_NULL, null=True, blank=True, related_name='history_logs')
    event_type = models.CharField(max_length=30, choices=EventType.choices)
    timestamp = models.DateTimeField(auto_now_add=True)
    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.SET_NULL, null=True, blank=True, help_text=_("User who triggered the event, if applicable"))
    # Stores extra details like comments, outcome, evaluated conditions, error messages
    details = models.JSONField(null=True, blank=True)

    class Meta:
        ordering = ('timestamp',)

    def __str__(self):
        return f"{self.timestamp} - {self.instance.id} - {self.event_type}"

```

**II. Core Engine Logic (`services.py` or `engine.py`)**

This is where the heavy lifting happens. It should be separate from views.

```python
# workflows/services.py
from django.utils import timezone
from django.db import transaction
from django.contrib.auth import get_user_model
from django.contrib.contenttypes.models import ContentType

from .models import WorkflowDefinition, WorkflowInstance, WorkflowTask, WorkflowHistory, AssigneeType, TaskStatus, InstanceStatus
# Assume User/Role/Org logic is available (e.g., in an 'accounts' app)
# from accounts.services import get_user_manager, get_users_in_role

# --- Placeholder for User/Org Service ---
# Replace with your actual user/role lookup logic
class OrgChartService:
    def get_user_manager(self, user):
        # Implement logic to find the manager of a user
        print(f"WARN: OrgChartService.get_user_manager not implemented for user {user.id}")
        return None # Placeholder

    def get_users_in_role(self, role_name):
        # Implement logic to find users belonging to a role/group
        print(f"WARN: OrgChartService.get_users_in_role not implemented for role {role_name}")
        User = get_user_model()
        # Example: return User.objects.filter(groups__name=role_name)
        return [] # Placeholder

org_chart_service = OrgChartService() # Instantiate or get service

# --- Rule Evaluator ---
class RuleEvaluator:
    def evaluate(self, condition_string, payload):
        # WARNING: Evaluating arbitrary strings is dangerous!
        # Use a safe evaluation library (like 'asteval' or build a simple parser)
        # For simplicity here, we'll do a basic check. Replace with robust implementation.
        print(f"Evaluating condition: '{condition_string}' with payload: {payload}")
        try:
            # Example simple condition: "payload.leave_days <= 3"
            if 'payload.' in condition_string:
                parts = condition_string.split(' ')
                if len(parts) == 3:
                    key = parts[0].replace('payload.', '')
                    op = parts[1]
                    value = parts[2]
                    payload_value = payload.get(key)

                    if payload_value is None: return False

                    # Basic comparison (expand significantly for production)
                    if op == '<=': return float(payload_value) <= float(value)
                    if op == '>': return float(payload_value) > float(value)
                    if op == '==':
                         # Try comparing as numbers first, then strings
                        try:
                            return float(payload_value) == float(value)
                        except ValueError:
                            return str(payload_value) == str(value).strip("'\"") # Handle string comparison
                    # Add more operators: !=, >=, <, etc.
                    # Add checks for different types (boolean, strings)
            print(f"WARN: Unsupported condition format: {condition_string}")
            return False # Default to false if condition unknown/malformed
        except Exception as e:
            print(f"ERROR evaluating condition '{condition_string}': {e}")
            return False

rule_evaluator = RuleEvaluator()

# --- Workflow Engine Service ---
class WorkflowEngineService:

    def _log_history(self, instance, event_type, node_id=None, task=None, user=None, details=None):
        WorkflowHistory.objects.create(
            instance=instance,
            node_id=node_id,
            task=task,
            event_type=event_type,
            user=user,
            details=details or {}
        )

    def _find_node_by_id(self, definition_json, node_id):
        nodes = definition_json.get('nodes', [])
        for node in nodes:
            if node.get('id') == node_id:
                return node
        return None

    def _find_outgoing_edges(self, definition_json, source_node_id):
        edges = definition_json.get('edges', [])
        return [edge for edge in edges if edge.get('source') == source_node_id]

    def _resolve_assignees(self, assignee_type, identifier, instance):
        User = get_user_model()
        users = []
        if assignee_type == AssigneeType.USER:
            try:
                users.append(User.objects.get(id=identifier)) # Assuming identifier is user ID
            except User.DoesNotExist:
                print(f"ERROR: Assignee user ID {identifier} not found.")
        elif assignee_type == AssigneeType.ROLE:
            users.extend(org_chart_service.get_users_in_role(identifier)) # Assuming identifier is role name
        elif assignee_type == AssigneeType.RULE:
            if identifier == 'RequesterManager':
                 # Assuming payload has 'requester_id'
                 requester_id = instance.payload.get('requester_id')
                 if requester_id:
                     try:
                        requester = User.objects.get(id=requester_id)
                        manager = org_chart_service.get_user_manager(requester)
                        if manager:
                            users.append(manager)
                     except User.DoesNotExist:
                         print(f"ERROR: Requester user ID {requester_id} not found.")
                 else:
                     print("ERROR: Cannot resolve 'RequesterManager', 'requester_id' missing in payload.")
            # Add more rules as needed
        return users

    def _create_task(self, instance, node_definition):
        node_id = node_definition.get('id')
        config = node_definition.get('data', {}).get('config', {}) # Assuming config is nested in node data
        assignee_type = config.get('assigneeType', AssigneeType.ROLE) # Default or get from config
        assignee_identifier = config.get('assigneeIdentifier', 'DefaultRole') # Default or get from config

        task = WorkflowTask.objects.create(
            instance=instance,
            node_id=node_id,
            task_type=node_definition.get('type', 'APPROVAL').upper(), # Use node type or config
            status=TaskStatus.PENDING,
            assignee_type=assignee_type,
            assignee_identifier=assignee_identifier,
            # due_date= # Calculate based on config.timeoutDuration if present
        )
        # Optionally, immediately resolve and link users if assignee_type is USER or if ROLE assignment is immediate
        # resolved_users = self._resolve_assignees(assignee_type, assignee_identifier, instance)
        # if resolved_users:
        #     task.assigned_users.set(resolved_users)
        #     task.status = TaskStatus.ASSIGNED # Or keep PENDING until claimed? Depends on logic.
        #     task.save()

        self._log_history(instance, WorkflowHistory.EventType.TASK_CREATED, node_id=node_id, task=task, details={'assignee': f"{assignee_type}:{assignee_identifier}"})
        # TODO: Send notifications to potential assignees
        # TODO: Schedule timeout check using Celery if config.timeoutDuration exists
        return task

    @transaction.atomic
    def start_instance(self, definition_id, initial_payload, triggered_by_object=None, user=None):
        try:
            definition = WorkflowDefinition.objects.get(id=definition_id, is_active=True)
        except WorkflowDefinition.DoesNotExist:
            print(f"ERROR: Active Workflow Definition {definition_id} not found.")
            # Or raise an exception
            return None

        instance = WorkflowInstance.objects.create(
            definition=definition,
            status=InstanceStatus.RUNNING, # Start as running
            payload=initial_payload,
            current_node_ids=[], # Will be set by finding the start node
            triggered_by_object=triggered_by_object
        )
        self._log_history(instance, WorkflowHistory.EventType.INSTANCE_STARTED, user=user, details={'initial_payload': initial_payload})

        # Find the 'start' node (assuming type='input' or type='start' from React Flow)
        start_node = None
        for node in definition.definition_json.get('nodes', []):
             # Adjust 'startNode' based on your frontend node type for Start event
            if node.get('type') == 'startNode':
                start_node = node
                break

        if not start_node:
            instance.status = InstanceStatus.FAILED
            instance.completed_at = timezone.now()
            instance.save()
            self._log_history(instance, WorkflowHistory.EventType.INSTANCE_FAILED, details={'error': 'Start node not found in definition'})
            print(f"ERROR: Start node not found for definition {definition.id}")
            return instance # Return failed instance

        # Immediately advance from the start node
        self.advance_workflow(instance, start_node.get('id'))
        return instance

    @transaction.atomic
    def advance_workflow(self, instance, completed_node_id, completion_data=None):
        if instance.status not in [InstanceStatus.RUNNING, InstanceStatus.SUSPENDED]:
             print(f"WARN: Attempted to advance non-running instance {instance.id} (status: {instance.status})")
             return

        definition_json = instance.definition.definition_json
        completed_node = self._find_node_by_id(definition_json, completed_node_id)

        if not completed_node:
            # This shouldn't happen if called correctly
            print(f"ERROR: Completed node ID {completed_node_id} not found in instance {instance.id}")
            # Consider marking instance as FAILED
            return

        # Log exit from the completed node
        self._log_history(instance, WorkflowHistory.EventType.NODE_EXITED, node_id=completed_node_id, details=completion_data)

        # Update current nodes (remove the one we just completed)
        current_nodes = list(instance.current_node_ids)
        if completed_node_id in current_nodes:
            current_nodes.remove(completed_node_id)

        next_node_ids_to_activate = []

        # Find outgoing edges from the completed node
        outgoing_edges = self._find_outgoing_edges(definition_json, completed_node_id)

        # Determine next node(s) based on node type and edges/conditions
        node_type = completed_node.get('type', '').lower()

        if node_type == 'decisionnode': # Or whatever your decision node type is
            evaluated_edge_found = False
            for edge in outgoing_edges:
                condition = edge.get('data', {}).get('condition', 'True') # Default to true if no condition
                # Evaluate condition
                if rule_evaluator.evaluate(condition, instance.payload):
                    next_node_ids_to_activate.append(edge.get('target'))
                    self._log_history(instance, WorkflowHistory.EventType.NODE_ENTERED, node_id=edge.get('target'), details={'condition': condition, 'result': True})
                    evaluated_edge_found = True
                    # If it's an exclusive gateway (XOR), break after first match
                    # If parallel (AND split) or inclusive (OR split), continue checking other edges
                    # Assuming exclusive for now:
                    break # Remove this if inclusive or parallel split needed

            if not evaluated_edge_found:
                 # Handle case where no condition matched (e.g., default path or error)
                 print(f"WARN: No condition matched for decision node {completed_node_id} in instance {instance.id}")
                 # Maybe look for an edge with no condition or a specific 'default' marker
                 # For now, we'll just stop this path
                 pass

        elif node_type == 'endnode': # Or your end node type
             # Workflow path ends here. If no other paths are active, complete the instance.
             pass # Logic below handles instance completion check

        else: # Standard node type (start, approval, service, notification etc.)
             # Assume a single outgoing path unless it's a parallel split node
             for edge in outgoing_edges:
                 next_node_ids_to_activate.append(edge.get('target'))
                 self._log_history(instance, WorkflowHistory.EventType.NODE_ENTERED, node_id=edge.get('target'))
                 # If it's a parallel split (AND), add all targets. If sequential, should only be one edge.

        # Process the newly activated nodes
        for next_node_id in next_node_ids_to_activate:
             if next_node_id not in current_nodes: # Avoid re-adding if merging parallel paths
                 current_nodes.append(next_node_id)

             next_node = self._find_node_by_id(definition_json, next_node_id)
             if not next_node:
                 print(f"ERROR: Next node ID {next_node_id} not found in definition.")
                 instance.status = InstanceStatus.FAILED
                 self._log_history(instance, WorkflowHistory.EventType.INSTANCE_FAILED, details={'error': f'Next node {next_node_id} not found'})
                 # Stop further processing for this path
                 continue

             next_node_type = next_node.get('type', '').lower()

             # Execute logic for the *newly entered* node
             if next_node_type in ['approvalnode', 'usertasknode']: # Check your specific types
                 self._create_task(instance, next_node)
                 # Path pauses here, waiting for task completion

             elif next_node_type == 'servicetasknode':
                 # TODO: Execute service task (e.g., call external API, update DB)
                 # This might be synchronous or asynchronous (using Celery)
                 # If synchronous and successful, immediately call advance_workflow(instance, next_node_id)
                 # If asynchronous, the Celery task must call advance_workflow on completion
                 print(f"INFO: Reached Service Task {next_node_id}. Execution not implemented.")
                 # Assuming synchronous success for now:
                 self.advance_workflow(instance, next_node_id, {'service_result': 'NotImplemented'})

             elif next_node_type == 'notificationnode':
                 # TODO: Send notification (e.g., using Celery)
                 print(f"INFO: Reached Notification Task {next_node_id}. Sending not implemented.")
                 # Notifications usually don't block, advance immediately
                 self.advance_workflow(instance, next_node_id, {'notification_sent': 'NotImplemented'})

             elif next_node_type == 'endnode':
                 # Reached an end node. This path is complete.
                 # The logic below will check if the whole instance should complete.
                 pass # No immediate action needed here

             elif next_node_type == 'decisionnode':
                  # Decision logic runs when *leaving* the node, so just enter it.
                  # Or, if conditions depend only on payload already present, could evaluate immediately?
                  # Standard practice is to evaluate on exit based on incoming data/task outcomes.
                  # If it acts purely on existing payload, could advance immediately:
                  # self.advance_workflow(instance, next_node_id)
                  pass # Assume evaluation happens on exit

             else: # Includes 'startNode' or other intermediate nodes
                 # No specific action, just advance automatically
                 self.advance_workflow(instance, next_node_id)

        # Update instance state
        instance.current_node_ids = current_nodes
        if not current_nodes: # No more active nodes means workflow finished
            instance.status = InstanceStatus.COMPLETED
            instance.completed_at = timezone.now()
            self._log_history(instance, WorkflowHistory.EventType.INSTANCE_COMPLETED)
            # TODO: Perform any final actions on workflow completion (e.g., update original Leave Request status)

        instance.save()

    @transaction.atomic
    def complete_task(self, task_id, user, outcome, completion_data=None):
        try:
            task = WorkflowTask.objects.select_related('instance').get(id=task_id)
        except WorkflowTask.DoesNotExist:
            print(f"ERROR: Task {task_id} not found.")
            raise ValueError("Task not found") # Or return error response

        # TODO: Add permission check: Is 'user' allowed to complete this task?
        # (Check task.assigned_users or resolve assignee identifier)

        if task.status == TaskStatus.COMPLETED:
            print(f"WARN: Task {task_id} already completed.")
            return task # Or raise specific error

        task.status = TaskStatus.COMPLETED
        task.outcome = outcome
        task.completion_data = completion_data or {}
        task.completed_at = timezone.now()
        task.completed_by = user
        task.save()

        self._log_history(
            task.instance,
            WorkflowHistory.EventType.TASK_COMPLETED,
            node_id=task.node_id,
            task=task,
            user=user,
            details={'outcome': outcome, 'completion_data': task.completion_data}
        )

        # Advance the workflow from the node that generated this task
        self.advance_workflow(task.instance, task.node_id, {'task_outcome': outcome, 'completion_data': task.completion_data})
        return task

# Instantiate the service for use in views
workflow_engine = WorkflowEngineService()
```

**III. Django REST Framework APIs (`views.py`, `serializers.py`, `urls.py`)**

Expose the models and service functions via REST APIs.

```python
# workflows/serializers.py
from rest_framework import serializers
from .models import WorkflowDefinition, WorkflowInstance, WorkflowTask, WorkflowHistory

class WorkflowDefinitionSerializer(serializers.ModelSerializer):
    class Meta:
        model = WorkflowDefinition
        fields = ('id', 'name', 'description', 'definition_json', 'version', 'is_active', 'created_at', 'updated_at')
        read_only_fields = ('id', 'version', 'created_at', 'updated_at') # Version managed internally potentially

class WorkflowInstanceSerializer(serializers.ModelSerializer):
    definition_name = serializers.CharField(source='definition.name', read_only=True)
    definition_version = serializers.IntegerField(source='definition.version', read_only=True)

    class Meta:
        model = WorkflowInstance
        fields = ('id', 'definition', 'definition_name', 'definition_version', 'status', 'payload', 'current_node_ids', 'started_at', 'completed_at', 'content_type', 'object_id')
        read_only_fields = ('id', 'definition_name', 'definition_version', 'status', 'current_node_ids', 'started_at', 'completed_at')

class WorkflowTaskSerializer(serializers.ModelSerializer):
    instance_id = serializers.UUIDField(source='instance.id', read_only=True)
    # Potentially include some payload summary from the instance for context
    instance_payload_summary = serializers.SerializerMethodField(read_only=True)

    class Meta:
        model = WorkflowTask
        fields = ('id', 'instance_id', 'node_id', 'task_type', 'status', 'assignee_type', 'assignee_identifier', 'assigned_users', 'due_date', 'outcome', 'completion_data', 'created_at', 'completed_at', 'completed_by', 'instance_payload_summary')
        read_only_fields = ('id', 'instance_id', 'node_id', 'task_type', 'status', 'assignee_type', 'assignee_identifier', 'assigned_users', 'due_date', 'created_at', 'completed_at', 'completed_by', 'instance_payload_summary', 'outcome') # Outcome set via complete action

    def get_instance_payload_summary(self, obj):
        # Example: return a subset of the instance payload for list views
        payload = obj.instance.payload
        return {
            'requester': payload.get('requester_name'),
            'leave_type': payload.get('leave_type'),
            'start_date': payload.get('start_date'),
        }

class WorkflowHistorySerializer(serializers.ModelSerializer):
    user_email = serializers.EmailField(source='user.email', read_only=True, allow_null=True) # Example

    class Meta:
        model = WorkflowHistory
        fields = ('id', 'instance', 'node_id', 'task', 'event_type', 'timestamp', 'user', 'user_email', 'details')
        read_only_fields = '__all__'

# --- Serializers for specific actions ---
class StartWorkflowSerializer(serializers.Serializer):
    definition_id = serializers.UUIDField(required=True)
    initial_payload = serializers.JSONField(required=True)
    # Optional: To link triggering object
    trigger_content_type_id = serializers.IntegerField(required=False, allow_null=True)
    trigger_object_id = serializers.UUIDField(required=False, allow_null=True)

class CompleteTaskSerializer(serializers.Serializer):
    outcome = serializers.CharField(required=True, max_length=100)
    completion_data = serializers.JSONField(required=False, default=dict)

```

```python
# workflows/views.py
from rest_framework import viewsets, status, mixins
from rest_framework.decorators import action
from rest_framework.response import Response
from rest_framework.permissions import IsAuthenticated # Add more specific permissions
from django.contrib.contenttypes.models import ContentType
from django.shortcuts import get_object_or_404

from .models import WorkflowDefinition, WorkflowInstance, WorkflowTask, WorkflowHistory
from .serializers import (
    WorkflowDefinitionSerializer, WorkflowInstanceSerializer, WorkflowTaskSerializer,
    WorkflowHistorySerializer, StartWorkflowSerializer, CompleteTaskSerializer
)
from .services import workflow_engine

class WorkflowDefinitionViewSet(viewsets.ModelViewSet):
    """
    API endpoint for managing Workflow Definitions.
    """
    queryset = WorkflowDefinition.objects.filter(is_active=True) # Default to active
    serializer_class = WorkflowDefinitionSerializer
    permission_classes = [IsAuthenticated] # TODO: Restrict to designers/admins

    # TODO: Add actions for activating/deactivating specific versions

class WorkflowInstanceViewSet(mixins.ListModelMixin,
                              mixins.RetrieveModelMixin,
                              viewsets.GenericViewSet):
    """
    API endpoint for viewing Workflow Instances and starting new ones.
    """
    queryset = WorkflowInstance.objects.all().select_related('definition')
    serializer_class = WorkflowInstanceSerializer
    permission_classes = [IsAuthenticated] # TODO: Permissions based on user involvement

    @action(detail=False, methods=['post'], serializer_class=StartWorkflowSerializer)
    def start_workflow(self, request):
        """
        Starts a new workflow instance.
        """
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        data = serializer.validated_data

        triggered_by_object = None
        if data.get('trigger_content_type_id') and data.get('trigger_object_id'):
             try:
                 ct = ContentType.objects.get_for_id(data['trigger_content_type_id'])
                 triggered_by_object = ct.get_object_for_this_type(id=data['trigger_object_id'])
             except ContentType.DoesNotExist:
                 return Response({"error": "Invalid trigger_content_type_id"}, status=status.HTTP_400_BAD_REQUEST)
             except ct.model_class().DoesNotExist:
                  return Response({"error": "Trigger object not found"}, status=status.HTTP_400_BAD_REQUEST)


        instance = workflow_engine.start_instance(
            definition_id=data['definition_id'],
            initial_payload=data['initial_payload'],
            triggered_by_object=triggered_by_object,
            user=request.user
        )

        if instance:
            instance_serializer = self.get_serializer(instance) # Use main serializer
            return Response(instance_serializer.data, status=status.HTTP_201_CREATED)
        else:
            # start_instance logs errors, return a generic failure or specific error
            return Response({"error": "Failed to start workflow instance."}, status=status.HTTP_400_BAD_REQUEST)

    @action(detail=True, methods=['get'])
    def history(self, request, pk=None):
        """
        Retrieves the history log for a specific workflow instance.
        """
        instance = self.get_object()
        history = WorkflowHistory.objects.filter(instance=instance).select_related('user', 'task')
        serializer = WorkflowHistorySerializer(history, many=True)
        return Response(serializer.data)

    # TODO: Add actions for cancelling, suspending, resuming instances (with permission checks)


class WorkflowTaskViewSet(mixins.ListModelMixin,
                          mixins.RetrieveModelMixin,
                          viewsets.GenericViewSet):
    """
    API endpoint for viewing tasks and completing them.
    """
    queryset = WorkflowTask.objects.all().select_related('instance', 'completed_by')
    serializer_class = WorkflowTaskSerializer
    permission_classes = [IsAuthenticated]

    def get_queryset(self):
        """
        Filter tasks based on the logged-in user.
        Users should only see tasks assigned to them or roles they belong to.
        """
        user = self.request.user
        # TODO: Implement proper filtering based on user ID, user roles/groups matching
        # task.assignee_identifier and task.assignee_type. This is complex.
        # Simple example: tasks directly assigned to user OR pending tasks for roles they are in
        from django.db.models import Q
        user_roles = user.groups.values_list('name', flat=True) # Example: Django groups as roles
        user_q = Q(assignee_type=AssigneeType.USER, assignee_identifier=str(user.id))
        role_q = Q(assignee_type=AssigneeType.ROLE, assignee_identifier__in=list(user_roles), status=TaskStatus.PENDING)
        assigned_q = Q(assigned_users=user) # If using M2M assignment

        # This query needs careful refinement based on your exact assignment logic
        # return WorkflowTask.objects.filter(user_q | role_q | assigned_q).distinct().select_related('instance', 'completed_by')

        # --- TEMPORARY: Return all tasks for demonstration ---
        print("WARN: WorkflowTaskViewSet queryset filtering is NOT implemented correctly for user permissions.")
        qs = super().get_queryset()
        status_filter = self.request.query_params.get('status')
        if status_filter:
            qs = qs.filter(status__iexact=status_filter)

        assignee_filter = self.request.query_params.get('assignee')
        if assignee_filter == 'me':
             # Replace this with the actual complex query above once implemented
             print("WARN: Filtering by 'assignee=me' is not fully implemented.")
             #qs = qs.filter(Q(assignee_identifier=str(user.id)) | Q(assigned_users=user)) # Simplistic version

        return qs


    @action(detail=True, methods=['post'], serializer_class=CompleteTaskSerializer)
    def complete(self, request, pk=None):
        """
        Completes a workflow task (e.g., Approve/Reject).
        """
        task = get_object_or_404(WorkflowTask, pk=pk) # Use get_object_or_404 for detail actions
        serializer = self.get_serializer(data=request.data)
        serializer.is_valid(raise_exception=True)
        data = serializer.validated_data

        try:
            # TODO: Add permission check here: can request.user complete this task?
            completed_task = workflow_engine.complete_task(
                task_id=task.id,
                user=request.user,
                outcome=data['outcome'],
                completion_data=data.get('completion_data')
            )
            task_serializer = self.serializer_class(completed_task) # Use main serializer
            return Response(task_serializer.data, status=status.HTTP_200_OK)
        except ValueError as e: # Catch specific errors from service
             return Response({"error": str(e)}, status=status.HTTP_400_BAD_REQUEST)
        except PermissionError as e: # Example permission error
             return Response({"detail": str(e)}, status=status.HTTP_403_FORBIDDEN)
        except Exception as e: # Catch unexpected errors
             print(f"ERROR completing task {task.id}: {e}")
             return Response({"error": "Failed to complete task."}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    # TODO: Add 'claim' action if needed for role-based tasks.

# --- Designer Config API (Simple Example) ---
from rest_framework.views import APIView

class WorkflowDesignerConfigView(APIView):
    permission_classes = [IsAuthenticated] # Allow any logged-in user to see config?

    def get(self, request, format=None):
        config = {
            "nodeTypes": [
                {"type": "startNode", "label": "Start Event", "icon": "play-circle", "configSchema": {}},
                {"type": "endNode", "label": "End Event", "icon": "stop-circle", "configSchema": {}},
                {
                    "type": "approvalNode",
                    "label": "Approval",
                    "icon": "check-square",
                    "configSchema": {
                        "assigneeType": {"label": "Assignee Type", "type": "select", "options": ["USER", "ROLE", "RULE"]},
                        "assigneeIdentifier": {"label": "Assignee (User ID/Role Name/Rule)", "type": "text"},
                        "timeoutDuration": {"label": "Timeout (seconds, 0=none)", "type": "number"},
                        "timeoutAction": {"label": "Timeout Action", "type": "select", "options": ["NOTIFY", "AUTO_REJECT", "AUTO_APPROVE", "ESCALATE"]},
                    }
                },
                {
                    "type": "decisionNode",
                    "label": "Decision",
                    "icon": "gateway",
                    "configSchema": {} # Conditions are usually on the edges
                },
                {
                    "type": "notificationNode",
                    "label": "Notification",
                    "icon": "bell",
                    "configSchema": {
                        "recipientType": {"label": "Recipient Type", "type": "select", "options": ["USER", "ROLE", "REQUESTER"]},
                        "recipientIdentifier": {"label": "Recipient (User ID/Role Name)", "type": "text"},
                        "messageTemplate": {"label": "Message Template", "type": "textarea"},
                    }
                 },
                # Add other node types: ServiceTask, FormTask, etc.
            ]
        }
        return Response(config)

```

```python
# workflows/urls.py
from django.urls import path, include
from rest_framework.routers import DefaultRouter
from . import views

router = DefaultRouter()
router.register(r'definitions', views.WorkflowDefinitionViewSet)
router.register(r'instances', views.WorkflowInstanceViewSet)
router.register(r'tasks', views.WorkflowTaskViewSet)

# Separate URL for the designer config as it's not a standard resource
urlpatterns = [
    path('', include(router.urls)),
    path('designer/config/', views.WorkflowDesignerConfigView.as_view(), name='workflow-designer-config'),
]
```

**IV. Integration & Next Steps**

1.  **Celery:** Integrate Celery & Celery Beat for:
    *   Running Service Tasks asynchronously.
    *   Sending notifications asynchronously.
    *   Scheduling timeout checks for pending `WorkflowTask`s based on `due_date`.
2.  **User/Org Integration:** Replace the placeholder `OrgChartService` with your actual logic for finding managers and role members.
3.  **Permissions:** Implement fine-grained permissions (e.g., using `Django Guardian` or custom DRF permission classes) to control who can design, start, view instances, and complete tasks.
4.  **Error Handling:** Enhance error handling and logging within the `WorkflowEngineService`. Define clear failure modes.
5.  **Rule Engine:** Replace the basic `RuleEvaluator` with a robust and secure library.
6.  **Triggering:** In your `LeaveRequest` saving logic (e.g., in the `save` method or a `post_save` signal handler), call `workflow_engine.start_instance` after a successful save.
7.  **Updating Related Object:** Implement the logic within the `WorkflowEngineService` (likely when an `endNode` is reached) to update the status of the `triggered_by_object` (e.g., the `LeaveRequest`).
8.  **Admin:** Register the models with the Django Admin for easy inspection.
9.  **Testing:** Write comprehensive tests for the models, services, and API views.

This Django structure provides a solid foundation for the workflow engine backend, separating concerns and utilizing Django/DRF features effectively. Remember to replace placeholders and implement TODOs according to your specific application requirements.